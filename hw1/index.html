<html>
	<head>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>
		<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
		<style>
			h1 {
				text-align: center;
			}

			.container {
				margin: 0 auto;
				padding: 60px 20%;
			}

			figure {
				text-align: center;
			}

			img {
				display: inline-block;
			}

			body {
				font-family: 'Inter', sans-serif;
			}
		</style>
	</head>
	<body>
		<div class="container">
			<h1>CS184/284A Spring 2025 Homework 1 Write-Up</h1>
			<div style="text-align: center;">Names: Helin Zhou and Isaac Gonzalez</div>

			<br>

			Link to webpage: <a href="https://cal-cs184.github.io/hw-webpages-su25-gonzaIke/">https://cal-cs184.github.io/hw-webpages-su25-gonzaIke/</a>

			<br>

			Link to GitHub repository: <a href="https://github.com/cal-cs184/hw-rasterizer-ggez">https://github.com/cal-cs184/hw-rasterizer-ggez</a>

			<figure>
				<img src="images/image1.png" alt="Lion" style="width:30%" />
			</figure>

			<!--
			We've already added one heading per task, to make your write-up as navigable when grading. Please fit your write-up within these sections!
			-->

			<h2>Overview</h2>
			<p>
				This assignment implements an SVG rasterizer that supports anti-aliasing, affine transformations, texture mapping, and more. Through this assignment, I gained an in-depth understanding of the basics of graphics such as triangle rasterization, oversampling antialiasing, affine transforms, center of gravity coordinates, pixel sampling, and multi-level texture sampling. <br>
				In the process of implementation, I encountered somewhat difficult problems such as sampling buffer management, transformation matrix derivation, and sampling algorithm efficiency. For example, how to manage the supersample buffer efficiently, how to implement the affine transformation matrix correctly, and how to make the sampling algorithm both correct and efficient. Through consulting information, debugging and discussing with classmates, I gradually solved these problems and gained a lot.
			</p>

			<h2>Task 1: Drawing Single-Color Triangles</h2>
			<p>
				I implemented triangle rasterization using bounding box scanning and edge function methods. The specific steps are as follows:
				<ul>
					<li>First, calculate the bounding box of the triangle, only traverse the pixels within the bounding box to avoid invalid calculations.</li>
					<li>For each pixel, the sampling point is the center of the pixel (i+0.5, j+0.5).</li>
					<li>Use the signed area of the three edges (cross product) to determine whether the sampling point is inside or on the edge of the triangle.</li>
					<li>If the sampling point is inside the triangle, call fill_pixel to fill the pixel.</li>
				</ul>
				My algorithm only traverses pixels within the bounding box of the triangle, and each pixel is only judged once, so the efficiency is consistent with the theoretical lower bound of "only sampling within the bounding box".<br>

				The following is the rendering result of <b>basic/test4.svg</b>, and the pixels at the boundary of the triangle are observed using the pixel inspector, and it can be seen that the color of the boundary pixel changes, indicating that the jaggies are obvious when not anti-aliasing.
			</p>
			<figure>
				<img src="images/screenshot_T1_t4.png" width="400px" />
				<figcaption>Task 1: test4.svg single-color triangle rasterization, pixel inspector shows boundary pixels.</figcaption>
			</figure>

			<h2>Task 2: Antialiasing by Supersampling</h2>
			<p>
				To solve the problem of jaggies, I implemented oversampling antialiasing (supersampling). The specific steps are as follows:
				<ul>
					<li>Each pixel is uniformly distributed with sqrt(sample_rate) x sqrt(sample_rate) sub-sampling points inside.</li>
					<li>Each sub-sampling point is independently judged whether it is inside the triangle, and the result is written into the supersample buffer.</li>
					<li>Finally, the color of each pixel is averaged by all sub-sampling points to obtain the final pixel color, achieving the effect of anti-aliasing.</li>
				</ul>
				In terms of data structure, the size of sample_buffer is width * height * sample_rate. fill_pixel fills all sub-sampling points for points and lines, rasterize_triangle samples each sub-sampling point, and resolve_to_framebuffer averages all sub-sampling points for each pixel. <br>
				Oversampling can effectively smooth the edges of triangles, reduce jaggies, and improve image quality.
			</p>
			<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td>
						<img src="images/screenshot_T2_t4_sr1.png" width="300px" />
						<figcaption>Sample rate = 1</figcaption>
					</td>
					<td>
						<img src="images/screenshot_T2_t4_sr4.png" width="300px" />
						<figcaption>Sample rate = 4</figcaption>
					</td>
					<td>
						<img src="images/screenshot_T2_t4_sr16.png" width="300px" />
						<figcaption>Sample rate = 16</figcaption>
					</td>
				</tr>
			</table>
			<p>
				As can be seen, the higher the sampling rate, the smoother the edges, and the fewer the jaggies. Especially in the thin corners and sloping edges of the triangle, when sample rate = 16, almost no jaggies can be seen, and when sample rate = 1, the jaggies are very obvious.
			</p>

			<h2>Task 3: Transforms</h2>
			<p>
				I made cubeman do a wave and run pose in my_robot.svg. Here's what I did:
				<ul>
					<li>Add a large negative rotation (forward swing/wave) of the right arm, such as <code>&lt;g transform="translate(90 -40) rotate(-60)"&gt;</code></li>
					<li>Left arm backswing, <code>&lt;g transform="translate(-90 -40) rotate(30)"&gt;</code></li>
					<li>Left leg front swing, <code>&lt;g transform="translate(-40 90) rotate(-30)"&gt;</code></li>
					<li>Right leg backswing, <code>&lt;g transform="translate(40 90) rotate(20)"&gt;</code></li>
					<li>Body overall forward lean, outermost <code>&lt;g transform="translate(250 250) rotate(-15)"&gt;</code></li>
				</ul>
				By modifying the transform attribute of each &lt;g&gt; element in SVG, and combining translate and rotate, I achieved independent transformations of limbs and bodies. <br>
				I hope cubeman looks lively, both waving and greeting as well as making running dynamics. By adjusting the angle of rotation of the limbs and body, the desired effect is achieved.
			</p>
			<figure>
				<img src="images/screenshot_T3_robot.png" width="300px" />
				<figcaption>Original cubeman</figcaption>
			</figure>
			<figure>
				<img src="images/screenshot_T3_myrobot.png" width="300px" />
				<figcaption>Waving cubeman</figcaption>
			</figure>
			<figure>
				<img src="images/screenshot_T3_myrobot_run.png" width="300px" />
				<figcaption>Running cubeman</figcaption>
			</figure>

			<h2>Task 4: Barycentric coordinates</h2>
			<p>
				In order to achieve a smooth transition of an object's medium such as color in this case, we will interpolate a specific value found on each vertex of the triangle and essentially spread it evenly across the area inside the triangle. 
				Barycentric coordinates are used in this case to calculate the weight, represented as alpha, beta, and gamma, that each position holds with respect to the color found in each vertex. It overall depends on how far the coordinate is from these vertices.
				By weight, I am referring to the cumulative value of the colored vertices at each point that when interpolation is complete, the triangle will have an appearance resembling a color wheel. 
				If we have a triangle with red, blue, and green vertices, the color inside the triangle will be a shade of the three colors along with the colors in-between, and the closer a point on the triangle is to a vertex, the more it will resemble the color of the vertex due to a higher respective weight.
			</p>
			<figure>
				<img src="images/task4sol_nearest.png" width="500px" />
				<figcaption>After applying the interpolation method with barycentric coordinates on test7.svg, it resembles a color wheel.</figcaption>
			</figure>

			<h2>Task 5: "Pixel sampling" for texture mapping</h2>
			<p>
				Pixel sampling is the process of taking the surrounding sample points of the texture point (u, v) and determining the cumulative color of that pixel by its area. It differs between both neighbor sampling (nearest) and interpolation sampling (bilinear).
			</p>
			  
			<p>
				The nearest sampling method follows a short and simple algorithm:
				<ol>
				  <li>Get the UV coordinates of the point.</li>
				  <li>Get the color from the closest texture point by rounding the coordinates.</li>
				</ol>
			</p>
			  
			<p>
				The bilinear sampling method follows a much longer process:
				<ol>
				  <li>The first step was to normalize the UV coords to texel space with both x and y, scaling them by the dimensions of the texture (width and height).</li>
				  <li>Then based on the point, I need to find the surrounding 4 texel coords.
					<ul>
					  <li>This was done by finding the max and min of both the x and y points using ceil and floor.</li>
					</ul>
				  </li>
				  <li>After that, the next goal is to get the color of each of the 4 texels.</li>
				  <li>Then, once I have all the colors, I need to account for the offsets of each texel coordinate.</li>
				  <li>
					Last would be to lerp out the weighted combination of the 4 texels to return the final color:
					<ul>
					  <li><strong>Linear interpolation (1D):</strong> <code>lerp(x, v0, v1) = v0 + x(v1 - v0)</code></li>
					  <li><strong>Two helper lerps:</strong>
						<ul>
						  <li><code>u0 = lerp(s, u00, u10)</code></li>
						  <li><code>u1 = lerp(s, u01, u11)</code></li>
						</ul>
					  </li>
					  <li><strong>Final vertical lerp, to get result:</strong>
						<ul>
						  <li><code>f(x, y) = lerp(t, u0, u1)</code></li>
						</ul>
					  </li>
					</ul>
				  </li>
				</ol>
			</p>
			
			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
					<img src="images/task5sol2_nearest_1fr.png" width="550px"/>
					<figcaption>Nearest sampling at 1 sample per pixel.</figcaption>
					</td>
					<td style="text-align: center;">
					<img src="images/task5sol2_nearest_16fr.png" width="550px"/>
					<figcaption>Nearest sampling at 16 samples per pixel.</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
					<img src="images/task5sol2_bilinear_1fr.png" width="550px"/>
					<figcaption>Bilinear sampling at 1 sample per pixel.</figcaption>
					</td>
					<td style="text-align: center;">
					<img src="images/task5sol2_bilinear_16fr.png" width="550px"/>
					<figcaption>Bilinear sampling at 16 samples per pixel.</figcaption>
					</td>
				</tr>
				</table>
			</div>
			<p>
				While the Nearest method is cheaper and faster, it comes at the trade of aliasing and pixelation at a close-up.
				The Bilinear method is quite the opposite, with noticeably cleaner visuals in deatil, along with a more expensive price and runtime.
			</p>

 
			<h2>Task 6: "Level Sampling" with mipmaps for texture mapping</h2>
			<p>
				Level sampling is the process of determining which mipmap level of a texture to sample from, based on how much a texture is being minified or magnified at a given screen-space location. This type of sampling adds-on to the texture mapping, but instead of assuming we always stay on Level 0, the lowest level with the highest resolution, we now can also choose a higher level for a lower resolution. We now have to account for the neighbors of the uv coordinates, in order to compute the mipmap level using the formula:
			</p>
			  
			<ul>
				<li><code>D = log2(max((du/dx)^2 + (dv/dx)^2, (du/dy)^2 + (dv/dy)^2))</code></li>
			</ul>
			  
			<p>
				We do this to support sampling different Mipmap levels, calculating the uv barycentric coordinates varying (x+1, y+1). In my implementation, I extended my texture sampling function to support multiple level sampling modes (<code>L_ZERO</code>, <code>L_NEAREST</code>, and <code>L_LINEAR</code>) based on the <code>SampleParams</code> struct passed from the rasterizer.
			</p>
			  
			<p>
				The three sampling techniques have their own tradeoffs. Pixel sampling is the fastest and least space intensive, but can produce visible aliasing that we don't want. Level sampling improves the image quality by selecting appropriate mipmap levels, but at the cost of extra memory for storing mipmaps. Supersampling provides the best anti-aliasing by averaging multiple samples per pixel, but it is the most expensive.
			</p>
			  

			<div style="display: flex; flex-direction: column; align-items: center;">
				<table style="width: 100%; text-align: center; border-collapse: collapse;">
				<tr>
					<td style="text-align: center;">
					<img src="images/task6sol_zeroL_nearestP.png" width="550px"/>
					<figcaption>Using Level Zero & Nearest Sampling.</figcaption>
					</td>
					<td style="text-align: center;">
					<img src="images/task6sol_zeroL_linearP.png" width="550px"/>
					<figcaption>Using Level Zero & Linear Sampling.</figcaption>
					</td>
				</tr>
				<tr>
					<td style="text-align: center;">
					<img src="images/task6sol_nearestL_nearestP.png" width="550px"/>
					<figcaption>Using Nearest Level & Nearest Sampling .</figcaption>
					</td>
					<td style="text-align: center;">
					<img src="images/task6sol_nearestL_linearP.png" width="550px"/>
					<figcaption>Using Nearest Level & Linear Sampling  .</figcaption>
					</td>
				</tr>
				</table>
			</div>

			
		</div>
	</body>
</html>